# Phase X Handoff: ABHY-Style Kinematic Map Fit Failure

## Executive Summary
We attempted to solve the "physics map" problem by performing an exact linear fit from the 9-dimensional kinematic space ($K_6$) to the 15-dimensional Forest Polytope ($P_F$), enforcing that matched facet inequalities $L_F(X) \ge 0$ scale proportionally to physical Mandelstam variables ($L_F(X) = \kappa_F s_{S(F)}$).

**Result:** The fit **failed** to find a physically viable map.
1.  **Inconsistency:** The system of equations for the 17 matched facets is rank-deficient and inconsistent. A maximal consistent subset contains only 11 facets.
2.  **Degeneracy:** To satisfy the consistent subset, the solver forced $\kappa_F = 0$ for 10 out of 11 facets. This maps the kinematic space to a boundary subspace where most slacks are permanently zero, which is unphysical.
3.  **Residue Check:** Confirmation with `residue_match_n6_with_fit_map.py` showed that physical poles $s_{ij} \to 0$ do not correspond to vanishing facets (except trivially for the $\kappa=0$ ones), failing the "Gate B" physics test.
4.  **Combinatorial Check:** We constructed the polar polytope of the affine hull and found exactly **108 vertices**, matching the number of rooted forests for $n=6, k=3$. This confirms the Forest Polytope itself is combinatorially correct, but its geometry is "rigid" in a way that prevents a simple linear embedding into kinematic space that captures all poles.

## Conclusion
The Forest Polytope (as a single convex polytope) **cannot** be the full positive geometry for $n=6$ gravity amplitudes under a linear map. The combinatorics of the facet intersections in the polytope do not match the intersection pattern of the kinematic poles (which all meet at $s_{ij}=0$). Future work should investigate **subdivisions** (finding the polytope as a sum of smaller geometries) or **non-linear maps** (unlikely for standard positive geometry).

---

## 1. Analysis of Fit Results (`kinematic_map_n6_fit.json` Summary)

- **Hull Dimensions:** Ambient 15, Intrinsic 11.
- **Matched Facets:** 17 physical candidates.
- **Consistent Subset:** 11 facets.
- **Scaling Factors ($\kappa$):**
    - Facet 1: $\kappa = 1.0$ (Only active facet)
    - Facets 2, 5, 6, 7, 8, 9, 10, 12, 13, 14: $\kappa = 0.0$ (Degenerate)
    - Facets 15, 16, 17, 18, 19, 20: Inconsistent (Affine mismatch)

## 2. New Scripts & Tools

### `src/posgeom/fit_kinematic_map_n6.sage`
Performs the linear algebra fit over $\mathbb{Q}$.
```python
import sys
import os
import json
import random
from sage.all import QQ, matrix, vector, Matrix, VectorSpace

# Adjust path to import local modules
sys.path.append(os.getcwd())

def load_json(path):
    with open(path, "r") as f:
        return json.load(f)

def get_s_map(u):
    """
    Given u (9-element vector), return full s_{ij} dictionary and s_S helper.
    u = [s01, s02, s03, s04, s12, s13, s14, s23, s24]
    """
    s01, s02, s03, s04, s12, s13, s14, s23, s24 = u
    
    s = {}
    s[(0,1)] = s01; s[(1,0)] = s01
    s[(0,2)] = s02; s[(2,0)] = s02
    s[(0,3)] = s03; s[(3,0)] = s03
    s[(0,4)] = s04; s[(4,0)] = s04
    s[(1,2)] = s12; s[(2,1)] = s12
    s[(1,3)] = s13; s[(3,1)] = s13
    s[(1,4)] = s14; s[(4,1)] = s14
    s[(2,3)] = s23; s[(3,2)] = s23
    s[(2,4)] = s24; s[(4,2)] = s24
    
    s05 = -(s01 + s02 + s03 + s04)
    s[(0,5)] = s05; s[(5,0)] = s05
    
    s15 = -(s01 + s12 + s13 + s14)
    s[(1,5)] = s15; s[(5,1)] = s15
    
    s25 = -(s02 + s12 + s23 + s24)
    s[(2,5)] = s25; s[(5,2)] = s25
    
    C3 = -(s03 + s13 + s23)
    C4 = -(s04 + s14 + s24)
    C5 = -(s05 + s15 + s25)
    
    s34 = (C3 + C4 - C5) / 2
    s35 = (C3 - C4 + C5) / 2
    s45 = (-C3 + C4 + C5) / 2
    
    s[(3,4)] = s34; s[(4,3)] = s34
    s[(3,5)] = s35; s[(5,3)] = s35
    s[(4,5)] = s45; s[(5,4)] = s45
    
    return s

def get_s_subset(s_map, subset):
    val = 0
    sub = sorted(list(subset))
    for idx, i in enumerate(sub):
        for j in sub[idx+1:]:
            val += s_map[(i,j)]
    return val

def solve_kinematic_map():
    print("Loading data...")
    facets = load_json("RESULTS/facet_dictionary_n6.json")
    hull_eq = load_json("RESULTS/facets_n6_eq_exact.json")
    
    equations = hull_eq["equations"]
    n_dim = 15
    n_eq = len(equations)
    
    E_rows = []
    b_vec = []
    
    for eq in equations:
        coeffs = [QQ(x) for x in eq]
        b_val = coeffs[0]
        row = coeffs[1:]
        E_rows.append(row)
        b_vec.append(b_val)
        
    E = matrix(QQ, E_rows)
    b_vec = vector(QQ, b_vec)
    
    try:
        X0 = E.solve_right(-b_vec)
    except ValueError:
        print("Error: No solution to hull equations!")
        return
        
    N_ker = E.right_kernel()
    N = N_ker.matrix().transpose()
    
    if N.ncols() != 11:
        print(f"Warning: Expected kernel dim 11, got {N.ncols()}")
        
    print(f"Hull parametrized: X = X0 + N*t, t in Q^{N.ncols()}")
    
    matched_facets = []
    for f in facets:
        if f["best_match"]["type"] in ["internal", "cut"]:
            matched_facets.append(f)
            
    print(f"Found {len(matched_facets)} matched facets for fitting.")
    
    M = len(matched_facets)
    n_t = 11
    n_u = 9
    
    # Check 1: Constant Part Consistency
    # (A_F N) t0 = - (b_F + A_F X0)
    print("Checking constant part consistency...")
    
    consistent_facets = []
    skipped_facets = []
    
    # Greedy selection of consistent facets
    current_rows = []
    current_rhs = []
    
    # First, shuffle or sort? 
    # Maybe prioritize by some metric? Let's just use the order in JSON.
    
    for f in matched_facets:
        f_coeffs = [QQ(x) for x in f["ineq_b_A"]]
        b_F = f_coeffs[0]
        A_F = vector(QQ, f_coeffs[1:])
        
        row = A_F * N
        rhs = -(b_F + A_F.dot_product(X0))
        
        # Test if adding this row preserves consistency
        test_rows = current_rows + [row]
        test_rhs = current_rhs + [rhs]
        
        mat_test = matrix(QQ, test_rows)
        vec_test = vector(QQ, test_rhs)
        
        # Rank check
        r = mat_test.rank()
        aug = mat_test.augment(vec_test)
        r_aug = aug.rank()
        
        if r == r_aug:
            # Consistent
            current_rows.append(row)
            current_rhs.append(rhs)
            consistent_facets.append(f)
        else:
            skipped_facets.append(f)

    print(f"Consistent facets: {len(consistent_facets)}/{len(matched_facets)}")
    if skipped_facets:
        print("Skipped facets (Affine mismatch):")
        for f in skipped_facets:
            print(f"  ID {f['facet_id']} (Subset {f['best_match']['subset']})")

    # Proceed with consistent facets only for t0 solving
    # But for T solving, we might still fit them?
    # If we skip them for t0, it means L_F(X0) != 0.
    # So L_F(X) = const + kappa s_S.
    # This violates Gate A (Exact Proportionality).
    # But we can't fix it if geometry prevents it.
    
    # We will fit the map using ONLY the consistent facets for the constraints.
    # The others will just be what they are.
    
    # Solve for t0 (particular solution for consistent set)
    # We need a t0 that satisfies the consistent equations.
    # And maybe minimizes error for others? No, just exact for consistent.
    
    mat_C = matrix(QQ, current_rows)
    vec_C = vector(QQ, current_rhs)
    # This system is consistent by construction.
    # It might be underdetermined (kernel > 0).
    # We can pick a particular t0, or leave free pars for T?
    # t0 is a constant vector. It doesn't depend on u.
    # Free parameters in t0 can be set to 0.
    
    t0_particular = mat_C.solve_right(vec_C)
    # kernel of C
    K_C = mat_C.right_kernel()
    # t0 = t0_particular + K_C * alpha. 
    # We can just use t0_particular for now.
    
    # Now setup T fit.
    # For consistent facets: L_F = kappa s_S. (const part matches 0).
    # For skipped facets: L_F = const + kappa s_S?
    # If we enforce L_F slope = kappa s_S slope, we can fit T.
    # But the constant term will remain non-zero.
    
    # Let's fit T using ALL matched facets (slopes can be matched even if intercept fails).
    # Equation: (A_F N) T u = kappa s_S(u)
    # (Constant parts cancel out for consistent, remain for skipped).
    # Wait, the equation we derived:
    # (A_F N) t0 + (A_F N) T u - k s_S = -(b + A X0)
    # If we use t0_particular, then for consistent facets:
    # (A_F N) t0_p = -(b + A X0).
    # So (A_F N) T u - k s_S = 0.
    
    # For skipped facets:
    # (A_F N) t0_p != -(b + A X0).
    # Let Rem = (b + A X0) + (A_F N) t0_p. (Non-zero residual).
    # Equation: (A_F N) T u - k s_S = -Rem
    # But LHS is linear in u. RHS is constant.
    # Only possible if LHS constant = RHS constant.
    # But T u is purely u-dependent? No, if u=0 -> 0.
    # s_S(0) = 0.
    # So LHS(0) = 0. RHS = -Rem != 0.
    # Contradiction for all u.
    
    # So skipped facets CANNOT satisfy the equation even with T freedom.
    # Because T multiplies u.
    # Unless we add a constant term to the map ansatz? t(u) = t0 + T u.
    # We already did. t0 is the constant.
    # The inconsistency is in t0.
    
    # So for skipped facets, we simply cannot enforce the condition.
    # We will exclude them from the fit entirely.
    
    matched_facets = consistent_facets
    
    # Re-setup full system with REDUCED set
    idx_t0 = 0
    idx_T = 11
    idx_k = 11 + 11*9
    total_vars = idx_k + len(matched_facets)
    M = len(matched_facets)
    
    system_rows = []
    system_rhs = []
    
    num_samples = 20
    
    print(f"Generating full system with {num_samples} samples (Consistent only)...")
    
    for sample_i in range(num_samples):
        u_vec = [QQ(random.randint(-10, 10)) for _ in range(n_u)]
        s_map = get_s_map(u_vec)
        
        for k_idx, facet in enumerate(matched_facets):
            f_coeffs = [QQ(x) for x in facet["ineq_b_A"]]
            b_F = f_coeffs[0]
            A_F = vector(QQ, f_coeffs[1:])
            subset = facet["best_match"]["subset"]
            s_S_val = get_s_subset(s_map, subset)
            
            coeff_t0 = A_F * N
            
            coeff_T = []
            for i in range(n_t):
                for j in range(n_u):
                    coeff_T.append(coeff_t0[i] * u_vec[j])
                    
            coeff_k = [0]*M
            coeff_k[k_idx] = -s_S_val
            
            const_val = b_F + A_F.dot_product(X0)
            rhs_val = -const_val
            
            row = list(coeff_t0) + coeff_T + coeff_k
            
            system_rows.append(row)
            system_rhs.append(rhs_val)
            
    # Add constraint kappa_0 = 1 to force non-trivial solution
    # Row: [0...0 (t0), 0...0 (T), 1, 0...0 (kappas)]
    # Index of kappa_0 is idx_k.
    constraint_row = [QQ(0)] * total_vars
    constraint_row[idx_k] = QQ(1)
    system_rows.append(constraint_row)
    system_rhs.append(QQ(1))

    print("Solving linear system...")
    A_sys = matrix(QQ, system_rows)
    B_sys = vector(QQ, system_rhs)
    
    try:
        Y = A_sys.solve_right(B_sys)
        print("Solution found!")
        
        t0 = Y[idx_t0 : idx_t0 + n_t]
        T_flat = Y[idx_T : idx_T + n_t*n_u]
        T_rows = []
        for i in range(n_t):
            T_rows.append(list(T_flat[i*n_u : (i+1)*n_u]))
        kappas = Y[idx_k : idx_k + M]
        
        def json_friendly(obj):
            if hasattr(obj, "numerator"): # Rational
                return float(obj)
            if isinstance(obj, list):
                return [json_friendly(x) for x in obj]
            return obj

        result = {
            "X0": json_friendly(list(X0)),
            "N": json_friendly([list(row) for row in N.rows()]), 
            "N_rows": json_friendly([list(r) for r in N.rows()]),
            "t0": json_friendly(list(t0)),
            "T": json_friendly(T_rows),
            "matched_facets": [],
            "edge_order": hull_eq["edges_ordered"]
        }
        
        print("\nMatched Facet Scalings (kappa):")
        for k_idx, k_val in enumerate(kappas):
            f = matched_facets[k_idx]
            print(f"Facet {f['facet_id']}: kappa = {k_val}")
            result["matched_facets"].append({
                "facet_id": f["facet_id"],
                "kappa": float(k_val),
                "subset": f["best_match"]["subset"]
            })
            
        out_path = "RESULTS/kinematic_map_n6_fit.json"
        with open(out_path, "w") as f:
            json.dump(result, f, indent=2)
        print(f"Map saved to {out_path}")
        
    except ValueError:
        print("No solution found. System may be inconsistent.")
        r = A_sys.rank()
        aug = A_sys.augment(B_sys)
        r_aug = aug.rank()
        print(f"Rank A: {r}, Rank Aug: {r_aug}")

if __name__ == "__main__":
    solve_kinematic_map()
```

### `src/posgeom/verify_kinematic_map_n6.sage`
Verifies the fitted map exactly on random points.
```python
import sys
import os
import json
import random
from sage.all import QQ, vector

# Adjust path to import local modules
sys.path.append(os.getcwd())

def load_json(path):
    with open(path, "r") as f:
        return json.load(f)

def get_s_map(u):
    s01, s02, s03, s04, s12, s13, s14, s23, s24 = u
    s = {}
    s[(0,1)] = s01; s[(1,0)] = s01
    s[(0,2)] = s02; s[(2,0)] = s02
    s[(0,3)] = s03; s[(3,0)] = s03
    s[(0,4)] = s04; s[(4,0)] = s04
    s[(1,2)] = s12; s[(2,1)] = s12
    s[(1,3)] = s13; s[(3,1)] = s13
    s[(1,4)] = s14; s[(4,1)] = s14
    s[(2,3)] = s23; s[(3,2)] = s23
    s[(2,4)] = s24; s[(4,2)] = s24
    
    s05 = -(s01 + s02 + s03 + s04)
    s[(0,5)] = s05; s[(5,0)] = s05
    s15 = -(s01 + s12 + s13 + s14)
    s[(1,5)] = s15; s[(5,1)] = s15
    s25 = -(s02 + s12 + s23 + s24)
    s[(2,5)] = s25; s[(5,2)] = s25
    
    C3 = -(s03 + s13 + s23)
    C4 = -(s04 + s14 + s24)
    C5 = -(s05 + s15 + s25)
    
    s34 = (C3 + C4 - C5) / 2
    s35 = (C3 - C4 + C5) / 2
    s45 = (-C3 + C4 + C5) / 2
    
    s[(3,4)] = s34; s[(4,3)] = s34
    s[(3,5)] = s35; s[(5,3)] = s35
    s[(4,5)] = s45; s[(5,4)] = s45
    return s

def get_s_subset(s_map, subset):
    val = 0
    sub = sorted(list(subset))
    for idx, i in enumerate(sub):
        for j in sub[idx+1:]:
            val += s_map[(i,j)]
    return val

def verify_map():
    print("Loading fit map...")
    fit = load_json("RESULTS/kinematic_map_n6_fit.json")
    facets = load_json("RESULTS/facet_dictionary_n6.json")
    
    X0 = vector(QQ, fit["X0"])
    # N is stored as list of lists (rows of N)
    N_rows = fit["N_rows"]
    # Reconstruct N as matrix. We need columns to be columns.
    # But sage matrix(rows) constructs from rows.
    # N_rows came from N.rows(). So matrix(N_rows) reconstructs N.
    from sage.all import matrix
    N = matrix(QQ, N_rows).transpose() # Wait. N.rows() gives rows of N.
    # In my fit script: N = N_ker.matrix().transpose().
    # So N is 15x11.
    # N.rows() gives 15 lists of length 11.
    # matrix(N_rows) gives 15x11 matrix. Correct.
    # Wait, in fit script I did: "N": json_friendly([list(row) for row in N.rows()])
    # So `N_rows` in JSON is list of 15 lists.
    # `matrix(QQ, fit["N_rows"])` creates 15x11 matrix. Correct.
    N = matrix(QQ, fit["N_rows"]) 
    
    t0 = vector(QQ, fit["t0"])
    T = matrix(QQ, fit["T"]) # 11x9
    
    matched_info = {m["facet_id"]: m for m in fit["matched_facets"]}
    
    print("Verifying on 50 fresh random points...")
    passes = 0
    fails = 0
    
    for i in range(50):
        u_vec = [QQ(random.randint(-20, 20)) for _ in range(9)]
        u = vector(QQ, u_vec)
        
        # Calculate t(s)
        # t = t0 + T*u
        t = t0 + T * u
        
        # Calculate X
        # X = X0 + N*t
        X = X0 + N * t
        
        # Check matched facets
        s_map = get_s_map(u_vec)
        
        point_pass = True
        
        for facet in facets:
            fid = facet["facet_id"]
            if fid not in matched_info:
                continue
            
            info = matched_info[fid]
            kappa = info["kappa"]
            subset = info["subset"]
            
            f_coeffs = [QQ(x) for x in facet["ineq_b_A"]]
            b_F = f_coeffs[0]
            A_F = vector(QQ, f_coeffs[1:])
            
            # L_F = b + A.X
            L_F = b_F + A_F.dot_product(X)
            
            # RHS = k * s_S
            s_S = get_s_subset(s_map, subset)
            rhs = kappa * s_S
            
            if abs(L_F - rhs) > 1e-10:
                print(f"Sample {i}: Facet {fid} Mismatch! L_F={float(L_F)}, RHS={float(rhs)}, Diff={float(L_F-rhs)}")
                point_pass = False
        
        if point_pass:
            passes += 1
        else:
            fails += 1
            
    print(f"\nVerification Results: {passes}/50 passed.")
    if fails == 0:
        print("Gate A Passed: Exact slack proportionality verified.")
    else:
        print("Gate A Failed.")

if __name__ == "__main__":
    verify_map()
```

### `src/posgeom/residue_match_n6_with_fit_map.py`
Physical residue checker (failed).
```python
import sys
import os
import json
import random
import math
from sage.all import RR, QQ, vector, matrix

sys.path.append(os.getcwd())

def load_json(path):
    with open(path, "r") as f:
        return json.load(f)

def compute_s_ij(lambdas, tildes, n=6):
    s = {}
    for i in range(n):
        for j in range(i+1, n):
            li = lambdas[i]
            lj = lambdas[j]
            ti = tildes[i]
            tj = tildes[j]
            
            # <i j> = det(li, lj)
            bracket_angle = li[0]*lj[1] - li[1]*lj[0]
            # [j i] = det(tj, ti) -- usually [ij] is defined such that s = <ij>[ji]
            bracket_square = tj[0]*ti[1] - tj[1]*ti[0] 
            
            val = bracket_angle * bracket_square
            s[(i,j)] = val
            s[(j,i)] = val
    return s

def run_residue_check_fit():
    print("Loading geometry...")
    fit = load_json("RESULTS/kinematic_map_n6_fit.json")
    facets = load_json("RESULTS/facet_dictionary_n6.json")
    facet_dict = {f["facet_id"]: f for f in facets}
    
    X0 = vector(RR, fit["X0"])
    N = matrix(RR, fit["N_rows"])
    t0 = vector(RR, fit["t0"])
    T = matrix(RR, fit["T"])
    
    matched_info = {m["facet_id"]: m for m in fit["matched_facets"]}
    active_facets = [fid for fid, m in matched_info.items() if abs(m["kappa"]) > 1e-9]
    zero_facets = [fid for fid, m in matched_info.items() if abs(m["kappa"]) <= 1e-9]
    
    print(f"Active Facets (kappa != 0): {active_facets}")
    print(f"Zero Facets (kappa == 0): {len(zero_facets)} facets")
    
    # Probes
    probes = []
    
    # 1. Collinear (0,1) -> s_01 -> 0
    def probe_01(eps):
        ts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
        ts[1] = ts[0] + eps
        return ts
    probes.append(("Collinear 0,1 (s_01->0)", probe_01))
    
    # 2. Multi-particle (0,1,2) -> s_012 -> 0
    # s_012 = s01 + s02 + s12
    # Make p0, p1, p2 collinear? Or sum p0+p1+p2 -> 0 (soft)?
    # Collinear limit: p1 || p0, p2 || p0.
    def probe_012(eps):
        ts = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]
        ts[1] = ts[0] + eps
        ts[2] = ts[0] + 2*eps
        return ts
    probes.append(("Triple 0,1,2 (s_012->0)", probe_012))
    
    epsilons = [1e-2, 1e-4, 1e-6, 1e-8]
    n = 6
    
    for name, func in probes:
        print(f"\n--- Probe: {name} ---")
        
        last_slacks = {}
        
        for eps in epsilons:
            ts = func(eps)
            lambdas = {i: vector(RR, [1.0, ts[i]]) for i in range(n)}
            
            # Solve for conserved tildes
            # Random base tildes
            random.seed(42)
            tildes = {}
            for i in range(n-2):
                tildes[i] = vector(RR, [random.uniform(-1,1), random.uniform(-1,1)])
            
            L_mat = matrix(RR, [[lambdas[n-2][0], lambdas[n-1][0]], 
                                [lambdas[n-2][1], lambdas[n-1][1]]])
            rhs_vec_t0 = vector(RR, [-sum(lambdas[i][0] * tildes[i][0] for i in range(n-2)),
                                     -sum(lambdas[i][1] * tildes[i][0] for i in range(n-2))])
            rhs_vec_t1 = vector(RR, [-sum(lambdas[i][0] * tildes[i][1] for i in range(n-2)),
                                     -sum(lambdas[i][1] * tildes[i][1] for i in range(n-2))])
            try:
                sol_t0 = L_mat.solve_right(rhs_vec_t0)
                sol_t1 = L_mat.solve_right(rhs_vec_t1)
                tildes[n-2] = vector(RR, [sol_t0[0], sol_t1[0]])
                tildes[n-1] = vector(RR, [sol_t0[1], sol_t1[1]])
            except ValueError:
                print(f"Skipping eps={eps} due to singular spinor config")
                continue

            s_dict = compute_s_ij(lambdas, tildes, n)
            
            u_vals = [
                s_dict[(0,1)], s_dict[(0,2)], s_dict[(0,3)], s_dict[(0,4)],
                s_dict[(1,2)], s_dict[(1,3)], s_dict[(1,4)],
                s_dict[(2,3)], s_dict[(2,4)]
            ]
            u = vector(RR, u_vals)
            
            # Calculate X and Slacks
            X = X0 + N * (t0 + T * u)
            
            slacks = {}
            for fid, m in matched_info.items():
                f_coeffs = [float(x) for x in facet_dict[fid]["ineq_b_A"]]
                b_F = f_coeffs[0]
                A_F = vector(RR, f_coeffs[1:])
                L_F = b_F + A_F.dot_product(X)
                slacks[fid] = L_F
            
            # Identify minimal slack among active and zero sets
            min_act = min([abs(slacks[f]) for f in active_facets]) if active_facets else 0
            min_zero = min([abs(slacks[f]) for f in zero_facets]) if zero_facets else 0
            
            print(f"eps={eps:.1e} | MinActive={min_act:.2e} | MinZero={min_zero:.2e}")
            last_slacks[eps] = (min_act, min_zero)
            
        # Scaling Check
        if len(epsilons) >= 2:
            e1, e2 = epsilons[-2], epsilons[-1]
            s1, z1 = last_slacks[e1]
            s2, z2 = last_slacks[e2]
            
            if s1 > 1e-15 and s2 > 1e-15:
                slope = (math.log(s2) - math.log(s1)) / (math.log(e2) - math.log(e1))
                print(f"Scaling Active: ~ eps^{slope:.2f}")
            else:
                print("Scaling Active: Undefined (Zero/Noise)")
                
            if z1 > 1e-15 and z2 > 1e-15:
                slope_z = (math.log(z2) - math.log(z1)) / (math.log(e2) - math.log(e1))
                print(f"Scaling Zero: ~ eps^{slope_z:.2f}")
            else:
                print("Scaling Zero: Exact Zero (consistent with kappa=0)")

if __name__ == "__main__":
    run_residue_check_fit()
```

### `src/posgeom/polar_from_facets_n6.sage`
Combinatorial validator.
```python
import sys
import os
import json
from sage.all import QQ, matrix, vector, MixedIntegerLinearProgram, Polyhedron

sys.path.append(os.getcwd())

def load_json(path):
    with open(path, "r") as f:
        return json.load(f)

def construct_polar():
    print("Loading hull data...")
    hull_eq = load_json("RESULTS/facets_n6_eq_exact.json")
    facets = load_json("RESULTS/facet_dictionary_n6.json")
    
    # We are in 15 dim, but polytope is 11 dim.
    # To construct polar, we should project to 11 dim intrinsic space?
    # Or work in 15 dim but polar will be infinite in normal directions?
    # Standard polar duality is for full-dim polytopes.
    # We should project to the affine hull.
    
    # Parametrization from hull equations
    # X = X0 + N * t
    # We found X0 and N in fit script. Let's re-derive or load.
    
    equations = hull_eq["equations"]
    # ... Solve E X = -b ...
    # Easier to just load the fit result which has X0, N.
    if os.path.exists("RESULTS/kinematic_map_n6_fit.json"):
        fit = load_json("RESULTS/kinematic_map_n6_fit.json")
        X0 = vector(QQ, fit["X0"])
        # N_rows contains the 15 rows of the 15x11 matrix N
        N = matrix(QQ, fit["N_rows"]) # 15x11
    else:
        print("Fit map not found, cannot define subspace.")
        return

    print("Projecting facets to intrinsic t-space (dim 11)...")
    # L_F(X) = b + A X = b + A(X0 + N t) = (b + A X0) + (A N) t
    # Let beta_F = b + A X0
    # Let alpha_F = A N (row vector)
    # Inequality: beta_F + alpha_F . t >= 0
    
    intrinsic_inequalities = [] # Format for Polyhedron: [beta, alpha...] so beta + alpha.x >= 0
    
    for f in facets:
        f_coeffs = [QQ(x) for x in f["ineq_b_A"]]
        b_F = f_coeffs[0]
        A_F = vector(QQ, f_coeffs[1:])
        
        beta = b_F + A_F.dot_product(X0)
        alpha = A_F * N # vector length 11
        
        # Sage Polyhedron expects [b, a1, ... an] for b + A x >= 0
        ieq = [beta] + list(alpha)
        intrinsic_inequalities.append(ieq)
        
    print(f"Constructing Polyhedron from {len(intrinsic_inequalities)} inequalities...")
    P = Polyhedron(ieqs=intrinsic_inequalities, base_ring=QQ)
    
    if P.is_empty():
        print("Polyhedron is empty!")
        return
        
    print(f"Polyhedron constructed. Vertices: {P.n_vertices()}")
    
    # Find interior point (Chebyshev center)
    # Sage doesn't have direct chebyshev center?
    # We can use P.center() if bounded?
    # Or just average of vertices.
    
    # Vertices might be many?
    if P.n_vertices() > 10000:
        print("Too many vertices to compute center from all.")
        center = P.vertices()[0].vector() # unsafe
    else:
        verts = P.vertices()
        center = sum(v.vector() for v in verts) / len(verts)
        
    print(f"Center t_c: {center}")
    
    # Check if center is strictly interior
    min_slack = min(beta + vector(QQ, alpha).dot_product(center) for beta, *alpha in intrinsic_inequalities)
    print(f"Min slack at center: {min_slack}")
    
    if min_slack <= 0:
        print("Center is not strictly interior. Using LP to find interior point.")
        # Setup LP
        p = MixedIntegerLinearProgram(maximization=True)
        t = p.new_variable(real=True)
        r = p.new_variable(real=True, nonnegative=True)
        p.set_objective(r[0])
        
        # For each ineq: beta + alpha.t >= r
        for ieq in intrinsic_inequalities:
            beta = ieq[0]
            alpha = ieq[1:]
            p.add_constraint(beta + sum(alpha[i]*t[i] for i in range(11)) >= r[0])
            
        try:
            p.solve()
            center = vector(QQ, p.get_values(t))
            min_slack = p.get_values(r)[0]
            print(f"LP Center found. Slack: {min_slack}")
        except Exception as e:
            print(f"LP failed: {e}")
            return

    # Shift to center
    # t = center + y
    # Ineq: beta + alpha(center + y) >= 0
    # (beta + alpha.center) + alpha.y >= 0
    # Let const_new = beta + alpha.center (positive)
    # Normalize: 1 + (alpha / const_new) . y >= 0
    # 1 >= - (alpha / const_new) . y
    # 1 >= w . y  where w = - alpha / const_new
    # This is standard form a.y <= 1.
    
    polar_vertices = []
    
    for ieq in intrinsic_inequalities:
        beta = ieq[0]
        alpha = vector(QQ, ieq[1:])
        const_val = beta + alpha.dot_product(center)
        
        if abs(const_val) < 1e-10:
            # Facet passes through center?? Should not happen if slack > 0
            continue
            
        w = - alpha / const_val
        polar_vertices.append(list(w))
        
    print(f"Computed {len(polar_vertices)} polar vertices.")
    
    # Save polar vertices
    # Also save center and N map to reconstruct full X
    # X_center = X0 + N * center
    
    def json_friendly(obj):
        if hasattr(obj, "numerator"):
            return float(obj)
        if isinstance(obj, list):
            return [json_friendly(x) for x in obj]
        return obj

    result = {
        "polar_vertices": json_friendly(polar_vertices),
        "center_t": json_friendly(list(center)),
        "center_slack": float(min_slack)
    }
    
    with open("RESULTS/polar_polytope_n6.json", "w") as f:
        json.dump(result, f, indent=2)
    print("Saved RESULTS/polar_polytope_n6.json")

if __name__ == "__main__":
    construct_polar()
```




